{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - Predict if an image is a cat or dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras_preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Avoid overfitting by transformations on dataset\n",
    "# Called image augmentation\n",
    "# Use imageDatGenerator to transform images\n",
    "trainDatagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "trainingSet = trainDatagen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size=(64,64), #final size of images\n",
    "    batch_size=32, #sample size\n",
    "    class_mode='binary' # either dog or cat, not both\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testDatagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "testSet = testDatagen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size=(64,64), #final size of images\n",
    "    batch_size=32, #sample size\n",
    "    class_mode='binary' # either dog or cat, not both\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1 - Convoluton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size = 3, activation='relu', input_shape=[64,64,3]))  #filters - amount of feature detectors, kernal size - number of rows, collums, activation - rectifer rulu, inputShape - three dimisions the rgb 64,64,3(RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2)) # Pool size - how much to condense(size of filter), strides - how much to shift to the right after pooling one frame, padding - valid (only do full cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a second convoultional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size = 3, activation='relu'))  #filters - amount of feature detectors, kernal size - number of rows, collums, activation - rectifer rulu, inputShape - three dimisions the rgb 64,64,3(RGB)\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2)) # Pool size - how much to condense(size of filter), strides - how much to shift to the right after pooling one frame, padding - valid (only do full cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3 - Flattening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten()) # No parameters needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 4 - Full Connection (add hidden layers of nuerons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) #units - amount of nuerons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Step 5 - Output Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) #units - amount of nuerons, only need 1 Cat/Dog, acitivation would be softmax if their are multiple class outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Train the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy']) #optimize using adam optimzer, calc weights to minmize loss, binary because cat/dog, metrics is optimzing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning the CNN on the Training set and evaluting it on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "250/250 [==============================] - 45s 177ms/step - loss: 0.6641 - accuracy: 0.5982 - val_loss: 0.6648 - val_accuracy: 0.6100\n",
      "Epoch 2/250\n",
      "250/250 [==============================] - 40s 159ms/step - loss: 0.5873 - accuracy: 0.6870 - val_loss: 0.5482 - val_accuracy: 0.7325\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 40s 158ms/step - loss: 0.5472 - accuracy: 0.7210 - val_loss: 0.5539 - val_accuracy: 0.7285\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 39s 158ms/step - loss: 0.5274 - accuracy: 0.7311 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 39s 158ms/step - loss: 0.5051 - accuracy: 0.7506 - val_loss: 0.5501 - val_accuracy: 0.7275\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 39s 158ms/step - loss: 0.4874 - accuracy: 0.7616 - val_loss: 0.5513 - val_accuracy: 0.7270\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 40s 159ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.4766 - val_accuracy: 0.7775\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 39s 156ms/step - loss: 0.4459 - accuracy: 0.7883 - val_loss: 0.4649 - val_accuracy: 0.7780\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 39s 156ms/step - loss: 0.4349 - accuracy: 0.7954 - val_loss: 0.4799 - val_accuracy: 0.7730\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 39s 157ms/step - loss: 0.4246 - accuracy: 0.8010 - val_loss: 0.4684 - val_accuracy: 0.7845\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 39s 157ms/step - loss: 0.4062 - accuracy: 0.8129 - val_loss: 0.4668 - val_accuracy: 0.7855\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 39s 156ms/step - loss: 0.4014 - accuracy: 0.8180 - val_loss: 0.4482 - val_accuracy: 0.8020\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 39s 157ms/step - loss: 0.3913 - accuracy: 0.8195 - val_loss: 0.5372 - val_accuracy: 0.7620\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 39s 155ms/step - loss: 0.3784 - accuracy: 0.8314 - val_loss: 0.4501 - val_accuracy: 0.7980\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.3656 - accuracy: 0.8355 - val_loss: 0.4553 - val_accuracy: 0.8045\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.3528 - accuracy: 0.8428 - val_loss: 0.4831 - val_accuracy: 0.7910\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.3476 - accuracy: 0.8451 - val_loss: 0.5107 - val_accuracy: 0.7745\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.3418 - accuracy: 0.8485 - val_loss: 0.4805 - val_accuracy: 0.7890\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.3230 - accuracy: 0.8591 - val_loss: 0.4975 - val_accuracy: 0.7930\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.3114 - accuracy: 0.8674 - val_loss: 0.5078 - val_accuracy: 0.7935\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 43s 172ms/step - loss: 0.2966 - accuracy: 0.8717 - val_loss: 0.4741 - val_accuracy: 0.8005\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.2939 - accuracy: 0.8761 - val_loss: 0.4826 - val_accuracy: 0.8095\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.2795 - accuracy: 0.8799 - val_loss: 0.5115 - val_accuracy: 0.8045\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 38s 153ms/step - loss: 0.2588 - accuracy: 0.8919 - val_loss: 0.4864 - val_accuracy: 0.8075\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 39s 154ms/step - loss: 0.2447 - accuracy: 0.8990 - val_loss: 0.5126 - val_accuracy: 0.8150\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 39s 155ms/step - loss: 0.2388 - accuracy: 0.9007 - val_loss: 0.5303 - val_accuracy: 0.8020\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 39s 154ms/step - loss: 0.2244 - accuracy: 0.9086 - val_loss: 0.5227 - val_accuracy: 0.8050\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 38s 153ms/step - loss: 0.2177 - accuracy: 0.9118 - val_loss: 0.5358 - val_accuracy: 0.8000\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 38s 152ms/step - loss: 0.2082 - accuracy: 0.9133 - val_loss: 0.6549 - val_accuracy: 0.7895\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 38s 150ms/step - loss: 0.1999 - accuracy: 0.9202 - val_loss: 0.6141 - val_accuracy: 0.7955\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 38s 153ms/step - loss: 0.1999 - accuracy: 0.9211 - val_loss: 0.6126 - val_accuracy: 0.7905\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 38s 152ms/step - loss: 0.1777 - accuracy: 0.9283 - val_loss: 0.6696 - val_accuracy: 0.7870\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 38s 153ms/step - loss: 0.1785 - accuracy: 0.9289 - val_loss: 0.6134 - val_accuracy: 0.7985\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.1676 - accuracy: 0.9333 - val_loss: 0.6285 - val_accuracy: 0.7980\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.1631 - accuracy: 0.9326 - val_loss: 0.7018 - val_accuracy: 0.7810\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 40s 158ms/step - loss: 0.1553 - accuracy: 0.9381 - val_loss: 0.7400 - val_accuracy: 0.7900\n",
      "Epoch 37/250\n",
      " 67/250 [=======>......................] - ETA: 25s - loss: 0.1482 - accuracy: 0.9440"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8w/pl5qfmyx7jzcj_x4rpfqc6wh0000gn/T/ipykernel_11067/1421647417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x = traning set, validation_data = TestSet, epochs = number of epochs to run (how many time to go through a set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn.fit(x = trainingSet, validation_data = testSet, epochs = 250) # x = traning set, validation_data = TestSet, epochs = number of epochs to run (how many time to go through a set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Making a single Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage = image.load_img('dataset/single_prediction/cat.png',target_size=(64,64)) # first argument is path to test image, second argument is scale mode (target size)\n",
    "testImage = image.img_to_array(testImage) #convert to a 2d array\n",
    "testImage = np.expand_dims(testImage, axis = 0) # same as batch size\n",
    "result = cnn.predict(testImage/255.0)\n",
    "#print(trainingSet.class_indices)\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction) #picture of levi a cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
